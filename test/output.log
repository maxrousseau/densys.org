============================= test session starts ==============================
platform linux -- Python 3.5.6, pytest-3.8.1, py-1.6.0, pluggy-0.7.1
rootdir: /home/max/Projects/flask-pfla/test, inifile:
collected 2 items

test_job.py .F                                                           [100%]

=================================== FAILURES ===================================
_____________________________ TestJob.test_execute _____________________________

self = <test_job.TestJob object at 0x7f8d7e0a65c0>
image_setup = <modules.job.Job object at 0x7f8d7e0a6d30>

    def test_execute(self, image_setup):
        sample_job = image_setup
>       assert sample_job.execute() != 0

test_job.py:53: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <modules.job.Job object at 0x7f8d7e0a6d30>

    def execute(self):
        """Method creating a new job entry to be saved in joblist.json
            Here we call the appropriate analysis depending on the task that was
    
            This method will store the job's hash, task, image path and current job
            status once completed.
    
            Parameters
            ----------
            None
    
            Returns
            ------
            result : string
                result of the specific analysis presented as a string.
            """
    
        result_str = None
        result_int = 0
    
    
        ###########################################################
        # face detetion: load network - prepare image - run network
        ###########################################################
    
        face_net = cv2.dnn.readNetFromCaffe(self.paths["prototxt"],
                                            self.paths["model"])
        image = cv2.imread(self.image)
        (height, width) = image.shape[:2]
        blob = cv2.dnn.blobFromImage(cv2.resize(image, (300, 300)),
                                     1.0,
                                     (300, 300),
                                     (103.93, 116.77, 123.68))
        face_net.setInput(blob)
        detections = face_net.forward()
    
        for i in range(0, detections.shape[2]):
            confidence = detections[0, 0, i, 2]
            if confidence > self.confidence:
    
                # multiple face warning!!!! --> if detections.shape[2] !=
                count = 0;
                if count > 0:
                    print("[ERROR] NO OR MULTIPLE FACES DETECTED IN IMAGE")
                    print("[INFO] cancelling job")
    
                else:
                    box = detections[0, 0, i, 3:7] * np.array([width, height, width,
                                                             height])
                    (startX, startY, endX, endY) = box.astype("int")
                    np_int_array = [startX, startY, endX, endY]
                    int32_array = []
                    for a in np_int_array:
                        int32_array.append(int(a))
                    self.json_obj["face_coord"] = int32_array
    
                    count += 1
    
        ###########################################################
        # facial landmarks: load face - create predictor - annotate
        ###########################################################
        dlib_rect = dlib.rectangle(int32_array[0],
                                   int32_array[1],
                                   int32_array[2],
                                   int32_array[3])
        predictor = dlib.shape_predictor(self.paths["shape_model"])
    
        landmarks = predictor(image, dlib_rect).parts()
    
        tuples_array = [(p.x, p.y) for p in landmarks]
        ldmk_coords = {}
        count = 1
        for x,y in tuples_array:
            x_coord = "X"+str(count)
            y_coord = "Y"+str(count)
            ldmk_coords[x_coord] = x
            ldmk_coords[y_coord] = y
            count += 1
    
        self.json_obj["ldmks_coords"] = ldmk_coords
    
    
        # run analysis functions
        if self.json_obj["task"] == "asym":
            asym_result = self.asym(ldmk_coords)
            self.json_obj["result"] = asym_result
            result_str = str(asym_result)
    
        elif self.json_obj["task"] == "lfh":
            lfh_result = self.lfh(ldmk_coords)
            self.json_obj["result"] = lfh_result
            result_str = str(lfh_result)
    
    #        elif self.json_obj["task"] == "med":
    #           None
    
        elif self.json_obj["task"] == "ratio1":
            ratio1_result = self.ratio1(ldmk_coords)
            self.json_obj["result"] = ratio1_result
            result_str = str(ratio1_result)
    
        elif self.json_obj["task"] == "ratio2":
            ratio2_result = self.ratio2(ldmk_coords)
            self.json_obj["result"] = ratio2_result
            result_str = str(ratio2_result)
    
        elif self.json_obj["task"] == "ratio3":
            ratio3_result = self.ratio3(ldmk_coords)
            self.json_obj["result"] = ratio3_result
            result_str = str(ratio3_result)
    
        else:
            print("[ERROR] TASK DOES NOT EXIST")
            print("[INFO] cancelling job")
    
        # write results to
        if not os.path.isfile(self.paths["joblist"]):
>           with open(self.paths["joblist"], "w") as outfile:
E           FileNotFoundError: [Errno 2] No such file or directory: '/home/max/Projects/flask-pfla/test/db/jobs/69af899d-dc16-4e40-bdb8-2df31b34474a.json'

../modules/job.py:371: FileNotFoundError
====================== 1 failed, 1 passed in 1.13 seconds ======================
